{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08992704-aa0c-436e-b1e6-df7bcc596ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tweepy/tweepy.git\n",
      "  Cloning https://github.com/tweepy/tweepy.git to /tmp/pip-req-build-e2bdlzwf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tweepy/tweepy.git /tmp/pip-req-build-e2bdlzwf\n",
      "  Resolved https://github.com/tweepy/tweepy.git to commit c7471ffc85e9d924e9f804d045aef9c6e0e2f45c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting oauthlib<4,>=3.2.0 (from tweepy==4.14.0)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.27.0 in /home/codespace/.local/lib/python3.10/site-packages (from tweepy==4.14.0) (2.31.0)\n",
      "Collecting requests-oauthlib<2,>=1.2.0 (from tweepy==4.14.0)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2023.5.7)\n",
      "Building wheels for collected packages: tweepy\n",
      "  Building wheel for tweepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tweepy: filename=tweepy-4.14.0-py3-none-any.whl size=98396 sha256=bffad670d75320d62da1eaf2bf19c35b5a470129cd55779839236473101f08fa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rbx4oubj/wheels/dc/75/73/ac2b7c1ac66d801a0b03c7707a2fc16e8689f792b585994c6f\n",
      "Successfully built tweepy\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/tweepy/tweepy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d50d1-d50f-4dce-b098-bae837f1d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c84b5-b5bc-4880-957e-23fe96ce5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an API\n",
    "\n",
    "# consumer_key = \"...\" #Your API/Consumer key \n",
    "# consumer_secret = \"...\" #Your API/Consumer Secret Key\n",
    "# access_token = \"...\"    #Your Access token key\n",
    "# access_token_secret = \"...\" #Your Access token Secret key\n",
    "# bearer_token = \"...\"\n",
    "\n",
    "#Pass in our twitter API authentication key\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret,\n",
    "    access_token, access_token_secret\n",
    ")\n",
    "\n",
    "#Instantiate the tweepy API\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "search_query = \"'ref''world cup'-filter:retweets AND -filter:replies AND -filter:links\"\n",
    "no_of_tweets = 100\n",
    "\n",
    "try:\n",
    "    #The number of tweets we want to retrieved from the search\n",
    "    tweets = api.search_tweets(q=search_query, lang=\"en\", count=no_of_tweets, tweet_mode ='extended')\n",
    "    \n",
    "    #Pulling Some attributes from the tweet\n",
    "    attributes_container = [[tweet.user.name, tweet.created_at, tweet.favorite_count, tweet.source, tweet.full_text] for tweet in tweets]\n",
    "\n",
    "    #Creation of co;lumn list to rename the columns in the dataframe\n",
    "    columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"]\n",
    "    \n",
    "    #Creation of Dataframe\n",
    "    tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "except BaseException as e:\n",
    "    print('Status Failed On,',str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb8396-8bb2-4fad-a883-f89a979001ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conduct ETL/EDA on a url of tweets after turning it into a DF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000c01a-3a7a-45d7-b2fa-f10a1eb22dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98428c-3f88-44be-8311-64393e61034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use pandas read_csv with sep='\\t' to read in the following 2 files available from the us naval academy\n",
    "\n",
    "# url file:\n",
    "url1 = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/keyword-tweets.txt'\n",
    "col_names = ['Sentiment', 'Tweet']\n",
    "\n",
    "# Download the data\n",
    "usn1 = pd.read_csv(url1, sep='\\t', names = col_names)\n",
    "usn1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c512b-1dfb-4529-9978-e0e46b247a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url file\n",
    "url2 = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/general-tweets.txt'\n",
    "col_names = ['Sentiment', 'Tweet']\n",
    "\n",
    "# Download the data\n",
    "usn2 = pd.read_csv(url2, sep='\\t', names = col_names)\n",
    "usn2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14438f41-aade-40fb-8848-07b2a6106899",
   "metadata": {},
   "source": [
    "**Reason: Use pandas read_csv to upload the data using the provided websites for further analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfeceb-194d-4a0d-a66c-d4db9838e42b",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully uploaded data from the two provided websites and displayed a portion of data from each website.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97539459-8852-46d3-9afd-ad08ab8e5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Concatenate these 2 data sets into a single data frame called LabeledTweets that has 2 columns, named Sentiment and Tweet\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "LabeledTweets = pd.concat([usn1, usn2], axis=0)\n",
    "\n",
    "# Rename the columns\n",
    "LabeledTweets.columns = ['Sentiment', 'Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7080170-23ea-4807-b3a0-601bdd1751e5",
   "metadata": {},
   "source": [
    "**Reason: To concatenate the two provided data sets into a single data frame and call it LabeledTweets. Then ensure LabeledTweets has 2 columns named Sentiment and Tweet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019df3-40fc-4eea-acc3-18a28d899655",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully concatenated the two dataframes and named the columns Sentiment and Tweet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e76e4-03f6-40a1-b0f0-2f4652d67f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Replace sentiment labels 'POLIT': 1, 'NOT': 0\n",
    "\n",
    "# Replace sentiment labels\n",
    "LabeledTweets['Sentiment'] = LabeledTweets['Sentiment'].replace({'POLIT': 1, 'NOT': 0})\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "# print(LabeledTweets)\n",
    "LabeledTweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9bb92-d920-4391-a8d8-44dc62b29a1d",
   "metadata": {},
   "source": [
    "**Reason: To replace the sentiment labels Polit with 1 and Not with 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0516f80-8104-4aa0-b3aa-9a12095b7be0",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully created a binary column for Sentiment instead of strings Polit and Not. This will help with further analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a333f-ee1c-4e1a-87bb-4299477f3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean the tweets by doing the following:\n",
    "\n",
    "# Removing all tokens that contain a \"@\". Remove the whole token, not just the character.\n",
    "# Removing all tokens that contain \"http\". Remove the whole token, not just the characters.\n",
    "# Replacing (not remove) all punctuation marks with a space (\" \")\n",
    "# Replacing all numbers with a space\n",
    "# Replacing all non ascii characters with a space\n",
    "# Converting all characters to lowercase\n",
    "# Striping the extra whitespaces\n",
    "# Lemmatizing tokens\n",
    "# and remembering not to remove stopwords because TfidfVectorizer will do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef97634-6c52-4c6e-86d3-517c3fa2be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, list_of_steps):\n",
    "    \n",
    "    for step in list_of_steps:\n",
    "        # step 1 remove entire tokens starting with ampersand\n",
    "        if step == 'remove_amp':\n",
    "            text = ' '.join([x for x in text.split() if not x.startswith(\"@\")])\n",
    "        # step 2 remove entire tokens starting with http    \n",
    "        elif step == 'remove_http':\n",
    "            text = ' '.join([x for x in text.split() if not x.startswith(\"http\")])\n",
    "        # step 3 replace punctuation with space     \n",
    "        elif step == 'replace_punctuation':\n",
    "            punct_exclude = set(string.punctuation)\n",
    "            for char in text:\n",
    "                if char in punct_exclude:\n",
    "                    text = text.replace(char, ' ')\n",
    "        # step 4 replace numbers    \n",
    "        elif step == 'replace_numbers':\n",
    "            for char in text:\n",
    "                try:\n",
    "                    if char.isdigit():\n",
    "                        text = text.replace(char, ' ')\n",
    "                except:\n",
    "                    pass\n",
    "        # step 5 replace non ascii characters with space    \n",
    "        elif step == 'replace_non_ascii':\n",
    "            for char in text:\n",
    "                if ord(char) >= 128:\n",
    "                    text = text.replace(char, ' ')\n",
    "        # step 6 turn all text to lowercase    \n",
    "        elif step == 'lower_case':\n",
    "            text = text.lower()\n",
    "        # step 7 strip the white space    \n",
    "        elif step == 'strip_whitespace':\n",
    "            text = ' '.join(text.split())\n",
    "        # step 8 lemmatizze the words into their stems    \n",
    "        elif step == 'lemmatize':\n",
    "            lmtzr = WordNetLemmatizer()\n",
    "            word_list = text.split(' ')\n",
    "            stemmed_words = [lmtzr.lemmatize(word) for word in word_list]\n",
    "            text = ' '.join(stemmed_words)\n",
    "    # finally return the processed text        \n",
    "    return text\n",
    "\n",
    "# Outline the steps\n",
    "step_list = ['remove_amp', 'remove_http', 'replace_punctuation', 'replace_numbers',\n",
    "            'replace_non_ascii', 'lower_case', 'strip_whitespace', 'lemmatize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab4f77-3f96-4999-8ea8-08026f53cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test string\n",
    "test_string = \"@cbigscat // can **12 http//www asoccen''t snwbrd &dggo li,on from aè  LIONSGATE\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53235cb9-c6e9-49f3-a5d9-a1468b831098",
   "metadata": {},
   "source": [
    "**Created a test string to test the steps prior to applying the function to the entire dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36c95a-df91-4856-a30a-92fe826b83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on test string\n",
    "clean_text = clean(test_string, step_list)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b759514-2402-436c-8a44-07b17a19299a",
   "metadata": {},
   "source": [
    "**Testing the steps was a success.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85656b5b-67f1-43de-9b6a-ed0bdbb23b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function on df by using the map function linked with the lambda function\n",
    "LabeledTweets['clean_tweet'] = LabeledTweets['Tweet'].map(lambda s: clean(s, step_list))\n",
    "\n",
    "# review dataframe\n",
    "LabeledTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf95e1-5685-4676-b4d0-37ebf565fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LabeledTweets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8eccf-44bd-426a-b3b6-905b0be1aa04",
   "metadata": {},
   "source": [
    "**Checking data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f679ffd-1ed0-4ece-838d-57fbdf389b02",
   "metadata": {},
   "source": [
    "**Reason:  To clean the tweets for legability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d17f7-6c08-4f00-b4b7-a99f4700ca7e",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully cleaned all the tweets using multiple methods making the tweets more legable compared to what they were originally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9018b84-cf1b-40cf-b428-322ba1052b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use TfidfVectorizer from sklearn to prepare the data for machine learning. Use max_features = 50; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55d869-e86c-46f0-93b5-9893f9178609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "# create a tfidVectorizer instance\n",
    "vectorizer = TfidfVectorizer(max_features = 50)\n",
    "\n",
    "# fit and transform our clean texts to a matrix\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "\n",
    "# extract the column names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# change the original matrix to a dense array\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32adfe9-f744-494e-895a-38160e0d3e9a",
   "metadata": {},
   "source": [
    "**Reason: To use TfidfVectorizer from sklearn to prepare the data for machine learning with the usage of max_features = 50.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859c73b-b59e-46c7-95ed-0cf78e1ebdaa",
   "metadata": {},
   "source": [
    "**Conclusion: All rows are still here prior to fitting which indicates that the data preservation. Successfully converted the text data into a format that can be used by machine learning algorithms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6abf6-0b44-4445-8626-60875157ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Use sklearn LogisticRegression to train a model on the results on 75% of the data.\n",
    "\n",
    "# 7. Determine the accuracy on the training data and the test data. Determine the baseline accuracy.\n",
    "\n",
    "# 8. Repeat steps 5, 6, and 7 with TfidfVectorizer max_features set to 5, 500, 5000, 50000 and discuss your accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237d6c3-7b12-4e4b-94dd-906cc94d6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e7e03-f2cc-4751-b61d-7488f40ee3c2",
   "metadata": {},
   "source": [
    "**The TF-IDF dataframe already has the method needed for analysis so I utilize the sentiment values as our targets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba7cbf-6739-4631-9679-924bf1c1a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f4d99-b9e3-481b-a8d0-ac775fb0b675",
   "metadata": {},
   "source": [
    "**3,003 is 75% of the original 4,004.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad8496-7ace-41df-ae98-960d398cf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab976712-512b-4cf6-998d-7667ef5e469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea16665-5c8d-4fb3-931a-444096a63a50",
   "metadata": {},
   "source": [
    "**I set the first model's max_feature parameter to 50. It produces a pretty good predictive model. The test accuracy is at 76% which portrays that it is not overfitting the data and is still giving a higher accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ac9bc-5c63-4b27-998f-6d6f04e7fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8b639-54fe-4fec-a44c-043b010fba3c",
   "metadata": {},
   "source": [
    "**With max features set at 50, predictive ability for our algorithm is 80%. Max features at 50 gives enough information for predicting sentiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d4cd6-7afc-42f3-b588-4496e99fd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a running list of dictionaries to hold the feature size and accuracy\n",
    "accuracy_dict = [{'feature_size': 50, 'accuracy': test_acc.round(3)}]\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d7485-f821-4f5e-ad66-76ad2f554418",
   "metadata": {},
   "source": [
    "**Max features set to: 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa6326-b8d2-43e0-ac91-f2724fce3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 5)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42dc55-fb95-4f74-94cf-53f197a433f3",
   "metadata": {},
   "source": [
    "**This dataframe appears too simplistic to be of use for a sentiment prediction. The words presented are practically all conjunctions or prepositions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e202486-3fe4-497f-8967-48eb7f769a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e514acf-275c-427d-a593-19946fa0b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d483b-1107-40e6-8f43-15c39c936ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b8d57a-5b56-4fe4-a00a-1b1ff33fad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da86c5-349d-4372-a715-8231d2847875",
   "metadata": {},
   "source": [
    "**We only have 5 features which creates a pretty useless model that is correct around 60% of the time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca906835-4cf5-477d-9102-4bdad3884329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4256e50-5454-4e1c-a23b-980d151394ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue to add to our running list of dictionaries\n",
    "accuracy_dict.append({'feature_size': 5, 'accuracy': test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07719cd4-94bc-41bc-9639-19059b113df8",
   "metadata": {},
   "source": [
    "**Max features set to: 500**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086912b-7426-4d0f-8c6b-78312b8f703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 500)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e1ac0-1b56-4105-8525-5cfddda70dc4",
   "metadata": {},
   "source": [
    "**This data frame appears to be reasonable. Words displayed are relevent and the number of features are deep enough to add value to our predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aedf17-31c8-4e48-9140-caac623f4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ed284-ba0b-433e-8279-57fbf8a041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a26b03-bff9-4990-a3cb-2fa59b3d544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed1ed9-8f52-4848-a1c1-76eb8a515817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c3153-17d2-4134-8250-7a0f49505119",
   "metadata": {},
   "source": [
    "**Max features set to 500  produces a higher accuracy than max features set to 50. I believe we are approaching the overfitting real**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c4fae-adc9-4750-a561-5d1b2e02aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e02109-83ea-462f-bf7a-1fb560d782c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict.append({'feature_size': 500, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2cbf-fba2-4183-a06d-c228fa174d83",
   "metadata": {},
   "source": [
    "**Max features set to: 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4830f-5e54-4379-9355-bc67e07521b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b5df2-64c6-4608-a8b0-1b806b3a2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d27a2-5b88-49ce-af5c-e1a170928710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea98b46-af11-4625-ae9c-292e28746b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e00ac-b2f6-49fe-9557-e9e6489a87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8108f-8462-40be-8ea9-b87865852450",
   "metadata": {},
   "source": [
    "**Max features set to 5000 seem to drop slightly compared to max features set at 500. Both were still above 80%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbf64f-e5e9-4da9-9b9e-eec07a75d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76303d7-e9df-4cd7-b94a-86d430b32d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict.append({'feature_size': 5000, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a028508-e49d-4eaf-b1f9-f43f18ebc08c",
   "metadata": {},
   "source": [
    "**Max features set to: 50000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8c7d3-f22d-499a-a5f7-a0ec4f43a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 50000)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53796c26-5cf9-4e49-83b2-15b17d049b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f04712-0e77-4785-a07c-7284717719b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204025b-1fe9-450a-a49d-686fe8bbd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc56175-2991-435d-a6d6-f23ed6cc9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3398568d-cb81-4341-a240-af0c7eb6f475",
   "metadata": {},
   "source": [
    "**Performance drops a little more with the max features set to 50000. Training accuracy is overfitting the data at this point. For our predictive model, I think we want to use lower max features. The higher number of features starts overfitting with accuracies getting above 90%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1ad04-1e4c-424c-aba0-31d6f8c4de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b20b8f-193c-447b-a93a-3c8755e1040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new values to dictionary\n",
    "accuracy_dict.append({'feature_size': 50000, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67110a9-a247-498d-887f-2eef37fdc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of accuracy and feature size\n",
    "accuracy_df = pd.DataFrame(accuracy_dict)\n",
    "accuracy_df = accuracy_df.set_index('feature_size')\n",
    "accuracy_df.columns = ['TestAccuracy']\n",
    "\n",
    "# display df\n",
    "accuracy_df = accuracy_df.sort_index(ascending=True)\n",
    "\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ed70e-0696-43dc-8e21-257ec56472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot on a graph, but take the log of the feature size and convert TestAccuracy to percent\n",
    "x = np.log(list(accuracy_df.index))\n",
    "y = np.array(accuracy_df['TestAccuracy'])*100\n",
    "\n",
    "plt.axes(title='Test Accuracy vs Feature Size', xlabel='Log(Feature Size)', ylabel='Percentage (%)')\n",
    "sns.lineplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ca5dc-ec31-42f5-bfe7-15b8e3302cfa",
   "metadata": {},
   "source": [
    "**Accuracy begins to trend as feature size increases. Predictive test accuracy significantly increases with feature size. Accuracy peaks and then drops slightly as Log(Feature Size) increases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5422935-6128-40c6-a306-fe8dd23c641e",
   "metadata": {},
   "source": [
    "**Reason: To use sklearn LogisticRegression to train a model on the results on 75% of the data, to determine the accuracy on the training data and the test data. Determine the baseline accuracy, and to repeat steps 5, 6, and 7 with TfidfVectorizer max_features set to 5, 500, 5000, 50000 and discuss your accuracies.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb19581-0f88-4acf-95f4-713839d46633",
   "metadata": {},
   "source": [
    "**Conclusion: Conclusions are spread throughout the analysis. See above.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
